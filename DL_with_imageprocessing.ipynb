{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Handson_DL.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wJPUL1ot5NYc"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import models, layers, utils, backend as K\n",
        "import matplotlib.pyplot as plt\n",
        "import shap\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.Sequential(name='Perceptron', layers=[\n",
        "                                                     layers.Dense(\n",
        "                                                         name='dense',\n",
        "                                                         input_dim=3,\n",
        "                                                         units=1,\n",
        "                                                         activation = 'relu'\n",
        "                                                     )\n",
        "])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vGG5GNAH-3WA",
        "outputId": "ae514d16-ee39-4824-a0e2-2aabb93bbdcd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Perceptron\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 1)                 4         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4\n",
            "Trainable params: 4\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_features = 10\n",
        "\n",
        "model = models.Sequential(name=\"DeepNN\", layers=[\n",
        "                                                 #hideen layer 1\n",
        "                                                 layers.Dense(name=\"h1\", input_dim=n_features,\n",
        "                                                 units=int(round(n_features+1)/2),\n",
        "                                                 activation='relu'),\n",
        "                                          layers.Dropout(rate=0.2),\n",
        "\n",
        "                                          #hidden layer 2\n",
        "                                                 layers.Dense(name=\"h2\", input_dim=n_features,\n",
        "                                                 units=int(round(n_features+1)/4),\n",
        "                                                 activation='relu'),\n",
        "                                          layers.Dropout(rate=0.2),\n",
        "                              ## layer output\n",
        "                              layers.Dense(name=\"output\", units=1, activation='sigmoid')\n",
        "\n",
        "])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ed2OxaulP3OX",
        "outputId": "97ca9950-308e-415d-fb67-148299f6b030"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"DeepNN\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " h1 (Dense)                  (None, 5)                 55        \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 5)                 0         \n",
            "                                                                 \n",
            " h2 (Dense)                  (None, 2)                 12        \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 2)                 0         \n",
            "                                                                 \n",
            " output (Dense)              (None, 1)                 3         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 70\n",
            "Trainable params: 70\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Using the Model method to define model instead of Sequential\n",
        "inputs = layers.Input(name=\"inputs\", shape=(n_features,1))\n",
        "#h1\n",
        "h1= layers.Dense(name=\"h1\", units=int(round((n_features+1)/2)),\n",
        "activation='relu')(inputs)\n",
        "h1 = layers.Dropout(rate=0.2)(h1)\n",
        "\n",
        "h2= layers.Dense(name=\"h2\", units=int(round((n_features+1)/4)),\n",
        "activation='relu')(h1)\n",
        "h2 = layers.Dropout(rate=0.2)(h2)\n",
        "\n",
        "output = layers.Dense(name=\"output\", units=1, activation='sigmoid')(h2)\n",
        "\n",
        "model = models.Model(inputs=inputs, outputs=output, name=\"DeepNN\")\n"
      ],
      "metadata": {
        "id": "6tYFEt_xTswI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train/validation\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "X = np.random.rand(1000,10)\n",
        "y = np.random.choice([1,0], size=1000)"
      ],
      "metadata": {
        "id": "faQfjYJYgFvq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Optional\n",
        "from numpy.random.mtrand import shuffle\n",
        "\n",
        "model.compile(optimizer='adam', loss='mean_absolute_error', metrics=['accuracy'])\n",
        "\n",
        "training = model.fit(x=X, y= y, batch_size=32, epochs=100,\n",
        "                     shuffle=True, verbose=1, validation_split=0.3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4J1_P64FgzoK",
        "outputId": "8a0efa51-bbf0-4ec8-d3f9-616321e21461"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "22/22 [==============================] - 1s 11ms/step - loss: 0.5001 - accuracy: 0.4932 - val_loss: 0.5006 - val_accuracy: 0.4879\n",
            "Epoch 2/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5001 - accuracy: 0.4927 - val_loss: 0.5007 - val_accuracy: 0.4867\n",
            "Epoch 3/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4999 - accuracy: 0.5017 - val_loss: 0.5007 - val_accuracy: 0.4867\n",
            "Epoch 4/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5001 - accuracy: 0.4995 - val_loss: 0.5007 - val_accuracy: 0.4867\n",
            "Epoch 5/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5001 - accuracy: 0.4907 - val_loss: 0.5006 - val_accuracy: 0.4873\n",
            "Epoch 6/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5000 - accuracy: 0.5002 - val_loss: 0.5006 - val_accuracy: 0.4873\n",
            "Epoch 7/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4999 - accuracy: 0.4984 - val_loss: 0.5007 - val_accuracy: 0.4867\n",
            "Epoch 8/100\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.5000 - accuracy: 0.5006 - val_loss: 0.5007 - val_accuracy: 0.4867\n",
            "Epoch 9/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5000 - accuracy: 0.5012 - val_loss: 0.5007 - val_accuracy: 0.4867\n",
            "Epoch 10/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4999 - accuracy: 0.5014 - val_loss: 0.5007 - val_accuracy: 0.4867\n",
            "Epoch 11/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5001 - accuracy: 0.5010 - val_loss: 0.5006 - val_accuracy: 0.4867\n",
            "Epoch 12/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5000 - accuracy: 0.5007 - val_loss: 0.5007 - val_accuracy: 0.4867\n",
            "Epoch 13/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5000 - accuracy: 0.5011 - val_loss: 0.5007 - val_accuracy: 0.4867\n",
            "Epoch 14/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5000 - accuracy: 0.5014 - val_loss: 0.5007 - val_accuracy: 0.4867\n",
            "Epoch 15/100\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.5000 - accuracy: 0.5016 - val_loss: 0.5006 - val_accuracy: 0.4867\n",
            "Epoch 16/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5001 - accuracy: 0.4915 - val_loss: 0.5006 - val_accuracy: 0.4867\n",
            "Epoch 17/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5000 - accuracy: 0.5010 - val_loss: 0.5007 - val_accuracy: 0.4867\n",
            "Epoch 18/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5000 - accuracy: 0.5009 - val_loss: 0.5007 - val_accuracy: 0.4867\n",
            "Epoch 19/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5000 - accuracy: 0.5016 - val_loss: 0.5007 - val_accuracy: 0.4867\n",
            "Epoch 20/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5000 - accuracy: 0.5008 - val_loss: 0.5007 - val_accuracy: 0.4867\n",
            "Epoch 21/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4999 - accuracy: 0.5013 - val_loss: 0.5007 - val_accuracy: 0.4867\n",
            "Epoch 22/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5001 - accuracy: 0.5008 - val_loss: 0.5007 - val_accuracy: 0.4867\n",
            "Epoch 23/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5000 - accuracy: 0.5003 - val_loss: 0.5007 - val_accuracy: 0.4867\n",
            "Epoch 24/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5000 - accuracy: 0.5004 - val_loss: 0.5007 - val_accuracy: 0.4867\n",
            "Epoch 25/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5000 - accuracy: 0.5017 - val_loss: 0.5008 - val_accuracy: 0.4867\n",
            "Epoch 26/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4999 - accuracy: 0.5012 - val_loss: 0.5008 - val_accuracy: 0.4867\n",
            "Epoch 27/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4999 - accuracy: 0.5021 - val_loss: 0.5008 - val_accuracy: 0.4867\n",
            "Epoch 28/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5001 - accuracy: 0.5001 - val_loss: 0.5008 - val_accuracy: 0.4867\n",
            "Epoch 29/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5000 - accuracy: 0.5010 - val_loss: 0.5008 - val_accuracy: 0.4867\n",
            "Epoch 30/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4999 - accuracy: 0.5019 - val_loss: 0.5008 - val_accuracy: 0.4867\n",
            "Epoch 31/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5000 - accuracy: 0.5012 - val_loss: 0.5008 - val_accuracy: 0.4867\n",
            "Epoch 32/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4999 - accuracy: 0.5010 - val_loss: 0.5008 - val_accuracy: 0.4867\n",
            "Epoch 33/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4999 - accuracy: 0.5016 - val_loss: 0.5008 - val_accuracy: 0.4867\n",
            "Epoch 34/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4999 - accuracy: 0.5011 - val_loss: 0.5008 - val_accuracy: 0.4867\n",
            "Epoch 35/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5000 - accuracy: 0.5011 - val_loss: 0.5008 - val_accuracy: 0.4867\n",
            "Epoch 36/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4999 - accuracy: 0.5011 - val_loss: 0.5008 - val_accuracy: 0.4867\n",
            "Epoch 37/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5000 - accuracy: 0.5018 - val_loss: 0.5009 - val_accuracy: 0.4867\n",
            "Epoch 38/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5000 - accuracy: 0.5007 - val_loss: 0.5008 - val_accuracy: 0.4867\n",
            "Epoch 39/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5000 - accuracy: 0.4989 - val_loss: 0.5008 - val_accuracy: 0.4867\n",
            "Epoch 40/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4999 - accuracy: 0.5012 - val_loss: 0.5008 - val_accuracy: 0.4867\n",
            "Epoch 41/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5000 - accuracy: 0.5014 - val_loss: 0.5009 - val_accuracy: 0.4867\n",
            "Epoch 42/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5000 - accuracy: 0.5007 - val_loss: 0.5009 - val_accuracy: 0.4867\n",
            "Epoch 43/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5000 - accuracy: 0.5014 - val_loss: 0.5009 - val_accuracy: 0.4867\n",
            "Epoch 44/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4999 - accuracy: 0.5019 - val_loss: 0.5009 - val_accuracy: 0.4867\n",
            "Epoch 45/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4999 - accuracy: 0.5016 - val_loss: 0.5009 - val_accuracy: 0.4867\n",
            "Epoch 46/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5001 - accuracy: 0.5005 - val_loss: 0.5009 - val_accuracy: 0.4867\n",
            "Epoch 47/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4999 - accuracy: 0.5013 - val_loss: 0.5009 - val_accuracy: 0.4867\n",
            "Epoch 48/100\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5009 - val_accuracy: 0.4867\n",
            "Epoch 49/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5000 - accuracy: 0.5009 - val_loss: 0.5009 - val_accuracy: 0.4867\n",
            "Epoch 50/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4999 - accuracy: 0.5013 - val_loss: 0.5009 - val_accuracy: 0.4867\n",
            "Epoch 51/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5000 - accuracy: 0.5002 - val_loss: 0.5009 - val_accuracy: 0.4867\n",
            "Epoch 52/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5000 - accuracy: 0.5004 - val_loss: 0.5009 - val_accuracy: 0.4867\n",
            "Epoch 53/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5001 - accuracy: 0.5005 - val_loss: 0.5010 - val_accuracy: 0.4867\n",
            "Epoch 54/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4999 - accuracy: 0.5016 - val_loss: 0.5009 - val_accuracy: 0.4867\n",
            "Epoch 55/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5000 - accuracy: 0.5010 - val_loss: 0.5010 - val_accuracy: 0.4867\n",
            "Epoch 56/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4999 - accuracy: 0.5009 - val_loss: 0.5010 - val_accuracy: 0.4867\n",
            "Epoch 57/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5000 - accuracy: 0.5012 - val_loss: 0.5009 - val_accuracy: 0.4867\n",
            "Epoch 58/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5000 - accuracy: 0.5005 - val_loss: 0.5010 - val_accuracy: 0.4867\n",
            "Epoch 59/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4999 - accuracy: 0.5012 - val_loss: 0.5010 - val_accuracy: 0.4867\n",
            "Epoch 60/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5001 - accuracy: 0.5006 - val_loss: 0.5010 - val_accuracy: 0.4867\n",
            "Epoch 61/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5000 - accuracy: 0.5005 - val_loss: 0.5010 - val_accuracy: 0.4867\n",
            "Epoch 62/100\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.5001 - accuracy: 0.5009 - val_loss: 0.5010 - val_accuracy: 0.4867\n",
            "Epoch 63/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5000 - accuracy: 0.5007 - val_loss: 0.5010 - val_accuracy: 0.4867\n",
            "Epoch 64/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5001 - accuracy: 0.5011 - val_loss: 0.5009 - val_accuracy: 0.4867\n",
            "Epoch 65/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4999 - accuracy: 0.5012 - val_loss: 0.5010 - val_accuracy: 0.4867\n",
            "Epoch 66/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5000 - accuracy: 0.5016 - val_loss: 0.5010 - val_accuracy: 0.4867\n",
            "Epoch 67/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5000 - accuracy: 0.5003 - val_loss: 0.5010 - val_accuracy: 0.4867\n",
            "Epoch 68/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5001 - accuracy: 0.5006 - val_loss: 0.5011 - val_accuracy: 0.4867\n",
            "Epoch 69/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4999 - accuracy: 0.5008 - val_loss: 0.5010 - val_accuracy: 0.4867\n",
            "Epoch 70/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4998 - accuracy: 0.5013 - val_loss: 0.5011 - val_accuracy: 0.4867\n",
            "Epoch 71/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5001 - accuracy: 0.5002 - val_loss: 0.5010 - val_accuracy: 0.4867\n",
            "Epoch 72/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4999 - accuracy: 0.5007 - val_loss: 0.5010 - val_accuracy: 0.4867\n",
            "Epoch 73/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5000 - accuracy: 0.5006 - val_loss: 0.5011 - val_accuracy: 0.4867\n",
            "Epoch 74/100\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4998 - accuracy: 0.5015 - val_loss: 0.5011 - val_accuracy: 0.4867\n",
            "Epoch 75/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4999 - accuracy: 0.5015 - val_loss: 0.5011 - val_accuracy: 0.4867\n",
            "Epoch 76/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4999 - accuracy: 0.5011 - val_loss: 0.5011 - val_accuracy: 0.4867\n",
            "Epoch 77/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4999 - accuracy: 0.5010 - val_loss: 0.5011 - val_accuracy: 0.4867\n",
            "Epoch 78/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5000 - accuracy: 0.5014 - val_loss: 0.5011 - val_accuracy: 0.4867\n",
            "Epoch 79/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4999 - accuracy: 0.5017 - val_loss: 0.5011 - val_accuracy: 0.4867\n",
            "Epoch 80/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4998 - accuracy: 0.5016 - val_loss: 0.5011 - val_accuracy: 0.4867\n",
            "Epoch 81/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4998 - accuracy: 0.5015 - val_loss: 0.5011 - val_accuracy: 0.4867\n",
            "Epoch 82/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5000 - accuracy: 0.5013 - val_loss: 0.5011 - val_accuracy: 0.4867\n",
            "Epoch 83/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4999 - accuracy: 0.5018 - val_loss: 0.5012 - val_accuracy: 0.4867\n",
            "Epoch 84/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4998 - accuracy: 0.5015 - val_loss: 0.5011 - val_accuracy: 0.4867\n",
            "Epoch 85/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4999 - accuracy: 0.5019 - val_loss: 0.5011 - val_accuracy: 0.4867\n",
            "Epoch 86/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4998 - accuracy: 0.5018 - val_loss: 0.5012 - val_accuracy: 0.4867\n",
            "Epoch 87/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4998 - accuracy: 0.5015 - val_loss: 0.5012 - val_accuracy: 0.4867\n",
            "Epoch 88/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5000 - accuracy: 0.5017 - val_loss: 0.5012 - val_accuracy: 0.4867\n",
            "Epoch 89/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4999 - accuracy: 0.5012 - val_loss: 0.5012 - val_accuracy: 0.4867\n",
            "Epoch 90/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5000 - accuracy: 0.5009 - val_loss: 0.5012 - val_accuracy: 0.4867\n",
            "Epoch 91/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4999 - accuracy: 0.5016 - val_loss: 0.5012 - val_accuracy: 0.4867\n",
            "Epoch 92/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4999 - accuracy: 0.5019 - val_loss: 0.5012 - val_accuracy: 0.4867\n",
            "Epoch 93/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5000 - accuracy: 0.5009 - val_loss: 0.5012 - val_accuracy: 0.4867\n",
            "Epoch 94/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5000 - accuracy: 0.5004 - val_loss: 0.5012 - val_accuracy: 0.4867\n",
            "Epoch 95/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4999 - accuracy: 0.5015 - val_loss: 0.5012 - val_accuracy: 0.4867\n",
            "Epoch 96/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5000 - accuracy: 0.5013 - val_loss: 0.5012 - val_accuracy: 0.4867\n",
            "Epoch 97/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5001 - accuracy: 0.5012 - val_loss: 0.5012 - val_accuracy: 0.4867\n",
            "Epoch 98/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4999 - accuracy: 0.5014 - val_loss: 0.5013 - val_accuracy: 0.4867\n",
            "Epoch 99/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5000 - accuracy: 0.5017 - val_loss: 0.5012 - val_accuracy: 0.4867\n",
            "Epoch 100/100\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4999 - accuracy: 0.5013 - val_loss: 0.5013 - val_accuracy: 0.4867\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def explainer_shap(model, X_names, X_instance, X_train=None, task=\"classification\", top_features=10):\n",
        "  # if X_train is not None, then deep learning\n",
        "  if X_train is None:\n",
        "    explainer = shap.TreeExplainer(model)\n",
        "    shap_values = explainer.shap_values(X_instance)\n",
        "  else:\n",
        "    explainer = shap.DeepExplainer(model, data=X_train[:100])\n",
        "    shap_values = explainer.shap_values(X_instance.reshape(1, -1))[0].reshape(-1)\n",
        "\n",
        "  if task == 'classification':\n",
        "    shap.decision_plot(explainer.expected_value, shap_values, link='logit', feature_order='importance',\n",
        "                       features=X_instance, feature_names=X_names, feature_display_range=slice(-1, -top_features-1, -1))\n",
        "\n",
        "  else:\n",
        "    shap.waterfall_plot(explainer.expected_value[0], shap_values,\n",
        "                        features=X_instance, feature_names=X_names, max_display=top_features)"
      ],
      "metadata": {
        "id": "V1IXIbOXjQaG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "data = load_iris()"
      ],
      "metadata": {
        "id": "-2w3bRWjouYn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = data['data']\n",
        "y = data['target']"
      ],
      "metadata": {
        "id": "S4c1SKcgsAqX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WF5GlEwU9EQo",
        "outputId": "a60315bf-c745-409d-ace6-dbd85829e7c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(150, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1hLKkDBn9G7N",
        "outputId": "ea823233-618e-4787-d5fe-6db5c5cb2b23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(150,)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import Sequential, models, utils\n",
        "from keras.layers import Dense\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras.utils import np_utils\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold"
      ],
      "metadata": {
        "id": "rvffEogOsIil"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def deepnn():\n",
        "  dnn = Sequential()\n",
        "  dnn.add(Dense(5,input_dim=(4), activation='relu'))\n",
        "  dnn.add(Dense(3, activation='softmax'))\n",
        "  dnn.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  return dnn"
      ],
      "metadata": {
        "id": "vqBNmNTStQk7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training = KerasClassifier(build_fn=deepnn, epochs=200, batch_size=5, verbose=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bGFDVRAGuQIf",
        "outputId": "78b842f0-663c-49b3-9b26-ee2c4a1f14f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "k_fold = KFold(n_splits=10, shuffle=True, random_state=7)"
      ],
      "metadata": {
        "id": "Ji-p8u-NvJEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3QizX34q6VrA",
        "outputId": "844bc603-f501-427d-ef4b-169045feb590"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(150, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XFzm-Ddr8AB3",
        "outputId": "7841c6e4-7c44-489f-ac8f-c9848590da5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(150,)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = cross_val_score(training, X, y, cv=k_fold)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_0Ub3pZDvjZo",
        "outputId": "e736f131-5a2d-4fba-de77-c5e92d7f647d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7fa4254659e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7fa425465320> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Image processing with Deep Processing"
      ],
      "metadata": {
        "id": "V7C5L0HvyHgb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import keras.datasets\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization, Dropout, Flatten\n",
        "\n"
      ],
      "metadata": {
        "id": "6DblJe-0yQMJ"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(train_x, train_y), (test_x, test_y) = keras.datasets.mnist.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQ15TwM1yvGV",
        "outputId": "d3e3805b-5ba5-450d-acaf-797256b75a4b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_x.shape)\n",
        "print(test_x.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LUkegr9ZzJzV",
        "outputId": "6ef6b09e-c4e1-42e2-adaf-935bbc7c93ab"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28)\n",
            "(10000, 28, 28)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BTnMab4CzilO",
        "outputId": "3cebc814-b6f8-4abf-c991-3f3cd62ae674"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000,)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classes = np.unique(train_y)\n",
        "classes_num = len(classes)"
      ],
      "metadata": {
        "id": "wd3IJ_y1zol5"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train\n",
        "plt.figure(figsize=[10,5])\n",
        "plt.subplot(121)\n",
        "plt.imshow(train_x[0, :, :], cmap='copper')\n",
        "plt.title(\"Ground Truth : {}\".format(train_y[0]))\n",
        "\n",
        "#test\n",
        "plt.figure(figsize=[10,5])\n",
        "plt.subplot(121)\n",
        "plt.imshow(test_x[0, :, :], cmap='copper')\n",
        "plt.title(\"Ground Truth : {}\".format(test_y[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 636
        },
        "id": "JF1jpul80I9I",
        "outputId": "3cd190c6-890b-4dae-917e-44c93f4510bb"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Ground Truth : 7')"
            ]
          },
          "metadata": {},
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#image processing\n",
        "train_x = train_x.reshape(train_x.shape[0], -1)\n",
        "test_x = test_x.reshape(test_x.shape[0], -1)"
      ],
      "metadata": {
        "id": "_SxCoJvd2xpM"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_x = train_x/255\n",
        "test_x = test_x/255"
      ],
      "metadata": {
        "id": "JpF1yrVd3rwg"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_y_one_hot = to_categorical(train_y)\n",
        "test_y_one_hot = to_categorical(test_y)"
      ],
      "metadata": {
        "id": "404lv62x37N2"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(512, activation='relu', input_shape=(train_x.shape[1],)))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dense(classes_num, activation='softmax'))\n",
        "\n",
        "\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "6o_XNlcs1bwD"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_x, train_y_one_hot, \n",
        "                    batch_size=256, epochs=10, verbose=True,\n",
        "                    validation_data=(test_x, test_y_one_hot))\n",
        "\n",
        "[test_loss, test_acc] = model.evaluate(test_x, test_y_one_hot)\n",
        "\n",
        "print(f'Loss = {test_loss}', f'accuracy = {test_acc}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UxU2Xopk5pMu",
        "outputId": "cac85790-30f3-4ecc-820a-7d1212fdd364"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "235/235 [==============================] - 8s 33ms/step - loss: 0.0076 - accuracy: 0.9976 - val_loss: 0.1160 - val_accuracy: 0.9795\n",
            "Epoch 2/10\n",
            "235/235 [==============================] - 7s 31ms/step - loss: 0.0066 - accuracy: 0.9979 - val_loss: 0.1288 - val_accuracy: 0.9771\n",
            "Epoch 3/10\n",
            "235/235 [==============================] - 7s 31ms/step - loss: 0.0063 - accuracy: 0.9981 - val_loss: 0.0933 - val_accuracy: 0.9841\n",
            "Epoch 4/10\n",
            "235/235 [==============================] - 7s 32ms/step - loss: 0.0054 - accuracy: 0.9983 - val_loss: 0.1108 - val_accuracy: 0.9833\n",
            "Epoch 5/10\n",
            "235/235 [==============================] - 7s 30ms/step - loss: 0.0054 - accuracy: 0.9983 - val_loss: 0.1306 - val_accuracy: 0.9804\n",
            "Epoch 6/10\n",
            "235/235 [==============================] - 7s 30ms/step - loss: 0.0046 - accuracy: 0.9985 - val_loss: 0.1174 - val_accuracy: 0.9817\n",
            "Epoch 7/10\n",
            "235/235 [==============================] - 7s 30ms/step - loss: 0.0046 - accuracy: 0.9986 - val_loss: 0.1226 - val_accuracy: 0.9826\n",
            "Epoch 8/10\n",
            "235/235 [==============================] - 7s 30ms/step - loss: 0.0052 - accuracy: 0.9985 - val_loss: 0.1236 - val_accuracy: 0.9836\n",
            "Epoch 9/10\n",
            "235/235 [==============================] - 7s 30ms/step - loss: 0.0038 - accuracy: 0.9988 - val_loss: 0.1330 - val_accuracy: 0.9823\n",
            "Epoch 10/10\n",
            "235/235 [==============================] - 7s 31ms/step - loss: 0.0033 - accuracy: 0.9990 - val_loss: 0.1360 - val_accuracy: 0.9814\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.1360 - accuracy: 0.9814\n",
            "Loss = 0.1359580159187317 accuracy = 0.9814000129699707\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CNN"
      ],
      "metadata": {
        "id": "qnmWeaGTKQAg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3,3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32,32,3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(32, (3,3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D((2,2)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Conv2D(64, (3,3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(64, (3,3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D((2,2)))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Conv2D(128, (3,3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(128, (3,3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D((2,2)))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Flatten())\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(10, activation = 'softmax'))\n"
      ],
      "metadata": {
        "id": "5mY9ZE_5KSLR"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#compile model\n",
        "opt = tensorflow.keras.optimizers.SGD(lr=0.001, momentum=0.9)\n",
        "model.compile(optimizer=opt, loss='categorital_crossentropy', metrics=['accuaracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fI9x08HSStly",
        "outputId": "303243ad-0d7c-4c36-ed51-f3f164e767e9"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history_cnn = model.fit(train_x, train_y_one_hot, epochs=30, batch_size=64,\n",
        "                        validation_data=(test_x, test_y_one_hot), verbose=1)"
      ],
      "metadata": {
        "id": "fFIUCV8WVDGx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transfer Learning"
      ],
      "metadata": {
        "id": "Nb5Kp0kD6zyk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "from keras.datasets import cifar100\n",
        "from keras.models import Sequential\n",
        "from keras.layers import UpSampling2D, GlobalAveragePooling2D, Dense, Dropout, BatchNormalization"
      ],
      "metadata": {
        "id": "3NfjqDrO620H"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "efficient_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(32,32,3))\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
        "\n",
        "x_test = x_test/255\n",
        "\n",
        "print(x_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jwW98gTD7hHl",
        "outputId": "bbdaabfd-147e-4395-b229-d252cbf21e5a"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
            "16711680/16705208 [==============================] - 0s 0us/step\n",
            "16719872/16705208 [==============================] - 0s 0us/step\n",
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
            "169009152/169001437 [==============================] - 3s 0us/step\n",
            "169017344/169001437 [==============================] - 3s 0us/step\n",
            "(10000, 32, 32, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_y_one_hot =  tensorflow.keras.utils.to_categorical(y_train)\n",
        "test_y_one_hot =  tensorflow.keras.utils.to_categorical(y_test)"
      ],
      "metadata": {
        "id": "bLkE0nku8JQg"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(efficient_model)\n",
        "\n",
        "model.add(GlobalAveragePooling2D())\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(.25))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "num_classes = 100\n",
        "model.add(Dense(num_classes, activation= 'softmax'))"
      ],
      "metadata": {
        "id": "CVTg0-7C8dA1"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in efficient_model.layers:\n",
        "  if isinstance(layer, BatchNormalization):\n",
        "    layer.trainable = True\n",
        "  else:\n",
        "    layer.trainable = False"
      ],
      "metadata": {
        "id": "vzFNqQkm9Hq_"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuaracy'])"
      ],
      "metadata": {
        "id": "f3ONKCAm9l4n"
      },
      "execution_count": 48,
      "outputs": []
    }
  ]
}